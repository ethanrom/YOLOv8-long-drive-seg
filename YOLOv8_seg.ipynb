{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ethanrom/YOLOv8-long-drive-seg/blob/main/YOLOv8_seg.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbvMlHd_QwMG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "262a036d-9707-4cb1-e921-1caf91c944e7"
      },
      "source": [
        "# Pip install method (recommended)\n",
        "%pip install ultralytics\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ultralytics YOLOv8.0.28 üöÄ Python-3.8.10 torch-1.13.1+cu116 CUDA:0 (Tesla T4, 15110MiB)\n",
            "Setup complete ‚úÖ (2 CPUs, 12.7 GB RAM, 23.6/78.2 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eq1SMWl6Sfn"
      },
      "source": [
        "# 2. Val\n",
        "Validate a model's accuracy on the [COCO](https://cocodataset.org/#home) dataset's `val` or `test` splits. The latest YOLOv8 [models](https://github.com/ultralytics/ultralytics#models) are downloaded automatically the first time they are used."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQPtK1QYVaD_"
      },
      "source": [
        "# Download COCO val\n",
        "import torch\n",
        "torch.hub.download_url_to_file('https://ultralytics.com/assets/coco2017val.zip', 'tmp.zip')  # download (780M - 5000 images)\n",
        "!unzip -q tmp.zip -d ../datasets && rm tmp.zip  # unzip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X58w8JLpMnjH",
        "outputId": "df71d7a8-f42f-473a-c143-75f033c58433",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Validate YOLOv8n on COCO128 val\n",
        "!yolo val model=yolov8n.pt data=coco128.yaml"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.0.24 üöÄ Python-3.8.10 torch-1.13.1+cu116 CUDA:0 (Tesla T4, 15110MiB)\n",
            "YOLOv8n summary (fused): 168 layers, 3151904 parameters, 0 gradients, 8.7 GFLOPs\n",
            "\n",
            "Dataset 'coco128.yaml' not found ‚ö†Ô∏è, missing paths ['/content/datasets/coco128/images/train2017']\n",
            "Downloading https://ultralytics.com/assets/coco128.zip to /content/datasets/coco128.zip...\n",
            "100% 6.66M/6.66M [00:00<00:00, 50.5MB/s]\n",
            "Unzipping /content/datasets/coco128.zip...\n",
            "Dataset download success ‚úÖ (0.5s), saved to \u001b[1m/content/datasets\u001b[0m\n",
            "\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
            "100% 755k/755k [00:00<00:00, 99.8MB/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/coco128/labels/train2017... 126 images, 2 backgrounds, 0 corrupt: 100% 128/128 [00:00<00:00, 1290.29it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/datasets/coco128/labels/train2017.cache\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 8/8 [00:06<00:00,  1.22it/s]\n",
            "                   all        128        929       0.64      0.537      0.605      0.446\n",
            "                person        128        254      0.797      0.677      0.764      0.538\n",
            "               bicycle        128          6      0.514      0.333      0.315      0.264\n",
            "                   car        128         46      0.813      0.217      0.273      0.168\n",
            "            motorcycle        128          5      0.687      0.887      0.898      0.685\n",
            "              airplane        128          6       0.82      0.833      0.927      0.675\n",
            "                   bus        128          7      0.491      0.714      0.728      0.671\n",
            "                 train        128          3      0.534      0.667      0.706      0.604\n",
            "                 truck        128         12          1      0.332      0.473      0.297\n",
            "                  boat        128          6      0.226      0.167      0.316      0.134\n",
            "         traffic light        128         14      0.734        0.2      0.202      0.139\n",
            "             stop sign        128          2          1      0.992      0.995      0.701\n",
            "                 bench        128          9      0.839      0.582       0.62      0.365\n",
            "                  bird        128         16      0.921      0.728      0.864       0.51\n",
            "                   cat        128          4      0.875          1      0.995      0.791\n",
            "                   dog        128          9      0.603      0.889      0.785      0.585\n",
            "                 horse        128          2      0.597          1      0.995      0.518\n",
            "              elephant        128         17      0.849      0.765        0.9      0.679\n",
            "                  bear        128          1      0.593          1      0.995      0.995\n",
            "                 zebra        128          4      0.848          1      0.995      0.965\n",
            "               giraffe        128          9       0.72          1      0.951      0.722\n",
            "              backpack        128          6      0.589      0.333      0.376      0.232\n",
            "              umbrella        128         18      0.804        0.5      0.643      0.414\n",
            "               handbag        128         19      0.424     0.0526      0.165     0.0889\n",
            "                   tie        128          7      0.804      0.714      0.674      0.476\n",
            "              suitcase        128          4      0.635      0.883      0.745      0.534\n",
            "               frisbee        128          5      0.675        0.8      0.759      0.688\n",
            "                  skis        128          1      0.567          1      0.995      0.497\n",
            "             snowboard        128          7      0.742      0.714      0.747        0.5\n",
            "           sports ball        128          6      0.716      0.433      0.485      0.278\n",
            "                  kite        128         10      0.817       0.45      0.569      0.184\n",
            "          baseball bat        128          4      0.551       0.25      0.353      0.175\n",
            "        baseball glove        128          7      0.624      0.429      0.429      0.293\n",
            "            skateboard        128          5      0.846        0.6        0.6       0.41\n",
            "         tennis racket        128          7      0.726      0.387      0.487       0.33\n",
            "                bottle        128         18      0.448      0.389      0.376      0.208\n",
            "            wine glass        128         16      0.743      0.362      0.584      0.333\n",
            "                   cup        128         36       0.58      0.278      0.404       0.29\n",
            "                  fork        128          6      0.527      0.167      0.246      0.184\n",
            "                 knife        128         16      0.564        0.5       0.59       0.36\n",
            "                 spoon        128         22      0.597      0.182      0.328       0.19\n",
            "                  bowl        128         28      0.648      0.643      0.618      0.491\n",
            "                banana        128          1          0          0      0.124     0.0379\n",
            "              sandwich        128          2      0.249        0.5      0.308      0.308\n",
            "                orange        128          4          1       0.31      0.995      0.623\n",
            "              broccoli        128         11      0.374      0.182      0.249      0.203\n",
            "                carrot        128         24      0.648      0.458      0.572      0.362\n",
            "               hot dog        128          2      0.351      0.553      0.745      0.721\n",
            "                 pizza        128          5      0.644          1      0.995      0.843\n",
            "                 donut        128         14      0.657          1       0.94      0.864\n",
            "                  cake        128          4      0.618          1      0.945      0.845\n",
            "                 chair        128         35      0.506      0.514      0.442      0.239\n",
            "                 couch        128          6      0.463        0.5      0.706      0.555\n",
            "          potted plant        128         14       0.65      0.643      0.711      0.472\n",
            "                   bed        128          3      0.698      0.667      0.789      0.625\n",
            "          dining table        128         13      0.432      0.615      0.485      0.366\n",
            "                toilet        128          2      0.615        0.5      0.695      0.676\n",
            "                    tv        128          2      0.373       0.62      0.745      0.696\n",
            "                laptop        128          3          1          0      0.451      0.361\n",
            "                 mouse        128          2          1          0     0.0625    0.00625\n",
            "                remote        128          8      0.843        0.5      0.605      0.529\n",
            "            cell phone        128          8          0          0     0.0549     0.0393\n",
            "             microwave        128          3      0.435      0.667      0.806      0.718\n",
            "                  oven        128          5      0.412        0.4      0.339       0.27\n",
            "                  sink        128          6       0.35      0.167      0.182      0.129\n",
            "          refrigerator        128          5      0.589        0.4      0.604      0.452\n",
            "                  book        128         29      0.629      0.103      0.346      0.178\n",
            "                 clock        128          9      0.788       0.83      0.875       0.74\n",
            "                  vase        128          2      0.376          1      0.828      0.795\n",
            "              scissors        128          1          1          0      0.249     0.0746\n",
            "            teddy bear        128         21      0.877      0.333      0.591      0.394\n",
            "            toothbrush        128          5      0.743        0.6      0.638      0.374\n",
            "Speed: 2.4ms pre-process, 7.8ms inference, 0.0ms loss, 3.3ms post-process per image\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "UEQwIzYcUnCC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "zeKxZiYhUTCS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"DATASET_DIRECTORY\"] = \"/content/datasets\""
      ],
      "metadata": {
        "id": "-LiIBTb1Uqs4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"zTxvKFTggq8hIQ8Ss6Bw\")\n",
        "project = rf.workspace(\"ku-iwzzj\").project(\"long-drive1\")\n",
        "dataset = project.version(1).download(\"yolov8\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rOgCaIhcUts3",
        "outputId": "1cc8aa70-939a-4383-fc62-a539f574445d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting roboflow\n",
            "  Downloading roboflow-0.2.29-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m49.0/49.0 KB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from roboflow) (1.15.0)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.8/dist-packages (from roboflow) (4.64.1)\n",
            "Collecting pyparsing==2.4.7\n",
            "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m67.8/67.8 KB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from roboflow) (3.2.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.8/dist-packages (from roboflow) (2.8.2)\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-0.21.1-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.8/dist-packages (from roboflow) (1.21.6)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.8/dist-packages (from roboflow) (6.0)\n",
            "Requirement already satisfied: certifi==2022.12.7 in /usr/local/lib/python3.8/dist-packages (from roboflow) (2022.12.7)\n",
            "Collecting cycler==0.10.0\n",
            "  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
            "Requirement already satisfied: opencv-python>=4.1.2 in /usr/local/lib/python3.8/dist-packages (from roboflow) (4.6.0.66)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.8/dist-packages (from roboflow) (1.4.4)\n",
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from roboflow) (2.25.1)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.8/dist-packages (from roboflow) (7.1.2)\n",
            "Requirement already satisfied: idna==2.10 in /usr/local/lib/python3.8/dist-packages (from roboflow) (2.10)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.8/dist-packages (from roboflow) (1.26.14)\n",
            "Collecting requests-toolbelt\n",
            "  Downloading requests_toolbelt-0.10.1-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m54.5/54.5 KB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: chardet==4.0.0 in /usr/local/lib/python3.8/dist-packages (from roboflow) (4.0.0)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9674 sha256=5616c8f4b27df87c1e57173e015c61af17024f5cb87ab7037ae37d6ea2aa1a32\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/a8/c3/3cf2c14a1837a4e04bd98631724e81f33f462d86a1d895fae0\n",
            "Successfully built wget\n",
            "Installing collected packages: wget, python-dotenv, pyparsing, cycler, requests-toolbelt, roboflow\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.0.9\n",
            "    Uninstalling pyparsing-3.0.9:\n",
            "      Successfully uninstalled pyparsing-3.0.9\n",
            "  Attempting uninstall: cycler\n",
            "    Found existing installation: cycler 0.11.0\n",
            "    Uninstalling cycler-0.11.0:\n",
            "      Successfully uninstalled cycler-0.11.0\n",
            "Successfully installed cycler-0.10.0 pyparsing-2.4.7 python-dotenv-0.21.1 requests-toolbelt-0.10.1 roboflow-0.2.29 wget-3.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "cycler",
                  "pyparsing"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "Dependency ultralytics<=8.0.20 is required but found version=8.0.28, to fix: `pip install ultralytics<=8.0.20`\n",
            "Downloading Dataset Version Zip in /content/datasets/long-drive1-1 to yolov8: 100% [8672164 / 8672164] bytes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Dataset Version Zip to /content/datasets/long-drive1-1 in yolov8:: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 457/457 [00:00<00:00, 2237.24it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY2VXXXu74w5"
      },
      "source": [
        "# 3. Train\n",
        "\n",
        "<p align=\"\"><a href=\"https://roboflow.com/?ref=ultralytics\"><img width=\"1000\" src=\"https://github.com/ultralytics/assets/raw/main/yolov8/banner-integrations.png\"/></a></p>\n",
        "\n",
        "Train YOLOv8 on [Detection](https://docs.ultralytics.com/tasks/detection/), [Segmentation](https://docs.ultralytics.com/tasks/segmentation/) and [Classification](https://docs.ultralytics.com/tasks/classification/) datasets."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!yolo task=segment mode=train model=yolov8m-seg.pt data={dataset.location}/data.yaml epochs=50 imgsz=640"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gnKxW6ALVEG4",
        "outputId": "f2c91234-34ec-4cf5-c6a8-b8e34bcc0abe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n-seg.pt to yolov8n-seg.pt...\n",
            "100% 6.73M/6.73M [00:00<00:00, 7.78MB/s]\n",
            "Ultralytics YOLOv8.0.28 üöÄ Python-3.8.10 torch-1.13.1+cu116 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\u001b[34m\u001b[1myolo/engine/trainer: \u001b[0mtask=segment, mode=train, model=yolov8n-seg.pt, data=/content/datasets/long-drive1-1/data.yaml, epochs=25, patience=50, batch=16, imgsz=640, save=True, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=False, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, image_weights=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, hide_labels=False, hide_conf=False, vid_stride=1, line_thickness=3, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, fl_gamma=0.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, save_dir=runs/segment/train\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
            "100% 755k/755k [00:00<00:00, 98.4MB/s]\n",
            "Overriding model.yaml nc=80 with nc=3\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.Conv                  [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.Conv                  [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.C2f                   [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.Conv                  [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.C2f                   [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.Conv                  [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.C2f                   [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.Conv                  [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.C2f                   [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.SPPF                  [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.C2f                   [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.C2f                   [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.Conv                  [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.C2f                   [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.Conv                  [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.C2f                   [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1   1004665  ultralytics.nn.modules.Segment               [3, 32, 64, [64, 128, 256]]   \n",
            "YOLOv8n-seg summary: 261 layers, 3264201 parameters, 3264185 gradients, 12.1 GFLOPs\n",
            "\n",
            "Transferred 381/417 items from pretrained weights\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 66 weight(decay=0.0), 77 weight(decay=0.0005), 76 bias\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/long-drive1-1/train/labels... 212 images, 0 backgrounds, 0 corrupt: 100% 212/212 [00:00<00:00, 1877.92it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/datasets/long-drive1-1/train/labels.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/long-drive1-1/valid/labels... 12 images, 0 backgrounds, 0 corrupt: 100% 12/12 [00:00<00:00, 1803.10it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/datasets/long-drive1-1/valid/labels.cache\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
            "Starting training for 25 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       1/25       3.5G      2.205      4.521      3.736       2.25         21        640: 100% 14/14 [00:19<00:00,  1.38s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.09it/s]\n",
            "                   all         12         27    0.00387      0.583     0.0091    0.00348    0.00197       0.25    0.00376    0.00197\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       2/25      3.69G      1.723       2.02      3.497      1.873         21        640: 100% 14/14 [00:09<00:00,  1.53it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.23it/s]\n",
            "                   all         12         27    0.00574      0.806      0.112     0.0862    0.00178       0.25      0.101       0.08\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       3/25      3.69G      1.663      1.402      3.053      1.791         31        640: 100% 14/14 [00:08<00:00,  1.60it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.19it/s]\n",
            "                   all         12         27    0.00751      0.939      0.186      0.138    0.00118      0.194       0.17      0.119\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       4/25      3.69G      1.553      1.273      2.561      1.643         28        640: 100% 14/14 [00:08<00:00,  1.59it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.09it/s]\n",
            "                   all         12         27     0.0068      0.933      0.224      0.156    0.00145      0.194       0.16     0.0741\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       5/25       3.7G      1.502      1.151       2.39      1.567         10        640: 100% 14/14 [00:08<00:00,  1.57it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.30it/s]\n",
            "                   all         12         27    0.00677      0.933      0.267      0.154    0.00123      0.139      0.115     0.0612\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       6/25       3.7G      1.439      1.053      2.121      1.541         21        640: 100% 14/14 [00:08<00:00,  1.57it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.20it/s]\n",
            "                   all         12         27      0.716      0.185      0.433      0.283      0.628      0.167      0.255      0.184\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       7/25       3.7G      1.406       1.18      2.083      1.517         23        640: 100% 14/14 [00:09<00:00,  1.54it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.21it/s]\n",
            "                   all         12         27       0.98      0.222      0.438      0.236      0.961      0.209      0.288      0.188\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       8/25       3.7G      1.381      1.081      1.982      1.456         24        640: 100% 14/14 [00:08<00:00,  1.60it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.21it/s]\n",
            "                   all         12         27      0.669      0.389      0.442       0.27      0.322      0.222      0.308      0.225\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       9/25       3.7G      1.343     0.9333      1.887      1.429         39        640: 100% 14/14 [00:08<00:00,  1.58it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.22it/s]\n",
            "                   all         12         27      0.515        0.5      0.476      0.306      0.638      0.293      0.296      0.204\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      10/25       3.7G       1.28      1.047      1.861      1.369         17        640: 100% 14/14 [00:09<00:00,  1.55it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.14it/s]\n",
            "                   all         12         27      0.966      0.261      0.457      0.295      0.629      0.216      0.268      0.162\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      11/25       3.7G      1.305      1.006      1.865      1.383         14        640: 100% 14/14 [00:08<00:00,  1.57it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.25it/s]\n",
            "                   all         12         27       0.49      0.482      0.552      0.352       0.64      0.333       0.33      0.268\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      12/25       3.7G      1.247     0.8806      1.736      1.362         16        640: 100% 14/14 [00:08<00:00,  1.58it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.26it/s]\n",
            "                   all         12         27      0.837      0.472      0.538      0.312      0.667      0.274      0.318      0.245\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      13/25       3.7G      1.288     0.9194      1.777      1.384         31        640: 100% 14/14 [00:09<00:00,  1.54it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.24it/s]\n",
            "                   all         12         27      0.782      0.506      0.568      0.304      0.652      0.306      0.309      0.222\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      14/25       3.7G      1.194     0.8972      1.683      1.295         20        640: 100% 14/14 [00:08<00:00,  1.59it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.23it/s]\n",
            "                   all         12         27       0.85      0.444      0.518      0.293      0.639      0.304        0.3      0.239\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      15/25       3.7G      1.251     0.9499      1.653      1.319         27        640: 100% 14/14 [00:08<00:00,  1.57it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.20it/s]\n",
            "                   all         12         27      0.685      0.496      0.463      0.294      0.667      0.275      0.318       0.24\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      16/25       3.7G      1.138     0.6672      1.712       1.38         18        640: 100% 14/14 [00:07<00:00,  1.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.17it/s]\n",
            "                   all         12         27      0.706      0.539      0.486      0.266      0.616      0.278      0.314      0.207\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      17/25       3.7G      1.083     0.6757      1.626      1.313         11        640: 100% 14/14 [00:05<00:00,  2.73it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.26it/s]\n",
            "                   all         12         27      0.467      0.604      0.509      0.297      0.661      0.306      0.328      0.225\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      18/25       3.7G     0.9961     0.6601      1.529      1.231          8        640: 100% 14/14 [00:05<00:00,  2.61it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.15it/s]\n",
            "                   all         12         27      0.515      0.639      0.587      0.341      0.613      0.306      0.296      0.231\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      19/25       3.7G      1.009     0.6247      1.525      1.251         15        640: 100% 14/14 [00:05<00:00,  2.66it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  1.73it/s]\n",
            "                   all         12         27      0.543      0.633      0.596      0.372      0.664      0.306      0.306      0.234\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      20/25       3.7G     0.9833     0.6115      1.463      1.232         13        640: 100% 14/14 [00:05<00:00,  2.36it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.20it/s]\n",
            "                   all         12         27      0.866      0.506      0.583      0.368      0.664      0.306      0.305      0.251\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      21/25       3.7G     0.9752     0.5981      1.425      1.225         13        640: 100% 14/14 [00:05<00:00,  2.60it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.22it/s]\n",
            "                   all         12         27      0.579      0.606      0.566      0.364      0.664      0.306      0.305      0.259\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      22/25       3.7G     0.9021     0.5798      1.407      1.186         11        640: 100% 14/14 [00:05<00:00,  2.55it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.23it/s]\n",
            "                   all         12         27      0.637      0.692      0.614      0.406      0.665      0.306      0.305      0.259\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      23/25       3.7G     0.8935     0.5776      1.359       1.17         10        640: 100% 14/14 [00:05<00:00,  2.61it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.21it/s]\n",
            "                   all         12         27      0.559      0.658      0.597      0.407      0.665      0.306      0.305      0.255\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      24/25       3.7G     0.8817       0.57      1.333       1.16         12        640: 100% 14/14 [00:05<00:00,  2.64it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.19it/s]\n",
            "                   all         12         27      0.489      0.602      0.579      0.382      0.664      0.306      0.305      0.256\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      25/25       3.7G     0.8439     0.5606      1.315      1.147          7        640: 100% 14/14 [00:05<00:00,  2.61it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  1.63it/s]\n",
            "                   all         12         27      0.507       0.66      0.637      0.393      0.998      0.306      0.305      0.267\n",
            "\n",
            "25 epochs completed in 0.064 hours.\n",
            "Optimizer stripped from runs/segment/train/weights/last.pt, 6.8MB\n",
            "Optimizer stripped from runs/segment/train/weights/best.pt, 6.8MB\n",
            "\n",
            "Validating runs/segment/train/weights/best.pt...\n",
            "Ultralytics YOLOv8.0.28 üöÄ Python-3.8.10 torch-1.13.1+cu116 CUDA:0 (Tesla T4, 15110MiB)\n",
            "YOLOv8n-seg summary (fused): 195 layers, 3258649 parameters, 0 gradients, 12.0 GFLOPs\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  1.63it/s]\n",
            "                   all         12         27      0.636      0.691      0.614      0.406      0.665      0.306      0.305      0.259\n",
            "                  pole         12         10      0.355        0.8      0.579      0.376          0          0          0          0\n",
            "                  road         12         12      0.924      0.917      0.915      0.671      0.995      0.917      0.915      0.776\n",
            "                  rock         12          5       0.63      0.356       0.35      0.171          1          0          0          0\n",
            "Speed: 0.2ms pre-process, 4.5ms inference, 0.0ms loss, 1.7ms post-process per image\n",
            "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Export\n",
        "\n",
        "Export a YOLOv8 model to any supported format with the `format` argument, i.e. `format=onnx`.\n",
        "\n",
        "- üí° ProTip: Export to [ONNX](https://onnx.ai/) or [OpenVINO](https://docs.openvino.ai/latest/index.html) for up to 3x CPU speedup.  \n",
        "- üí° ProTip: Export to [TensorRT](https://developer.nvidia.com/tensorrt) for up to 5x GPU speedup.\n",
        "\n",
        "\n",
        "| Format                                                                     | `format=`          | Model                     |\n",
        "|----------------------------------------------------------------------------|--------------------|---------------------------|\n",
        "| [PyTorch](https://pytorch.org/)                                            | -                  | `yolov8n.pt`              |\n",
        "| [TorchScript](https://pytorch.org/docs/stable/jit.html)                    | `torchscript`      | `yolov8n.torchscript`     |\n",
        "| [ONNX](https://onnx.ai/)                                                   | `onnx`             | `yolov8n.onnx`            |\n",
        "| [OpenVINO](https://docs.openvino.ai/latest/index.html)                     | `openvino`         | `yolov8n_openvino_model/` |\n",
        "| [TensorRT](https://developer.nvidia.com/tensorrt)                          | `engine`           | `yolov8n.engine`          |\n",
        "| [CoreML](https://github.com/apple/coremltools)                             | `coreml`           | `yolov8n.mlmodel`         |\n",
        "| [TensorFlow SavedModel](https://www.tensorflow.org/guide/saved_model)      | `saved_model`      | `yolov8n_saved_model/`    |\n",
        "| [TensorFlow GraphDef](https://www.tensorflow.org/api_docs/python/tf/Graph) | `pb`               | `yolov8n.pb`              |\n",
        "| [TensorFlow Lite](https://www.tensorflow.org/lite)                         | `tflite`           | `yolov8n.tflite`          |\n",
        "| [TensorFlow Edge TPU](https://coral.ai/docs/edgetpu/models-intro/)         | `edgetpu`          | `yolov8n_edgetpu.tflite`  |\n",
        "| [TensorFlow.js](https://www.tensorflow.org/js)                             | `tfjs`             | `yolov8n_web_model/`      |\n",
        "| [PaddlePaddle](https://github.com/PaddlePaddle)                            | `paddle`           | `yolov8n_paddle_model/`   |\n",
        "\n"
      ],
      "metadata": {
        "id": "nPZZeNrLCQG6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!yolo export model=yolov8n.pt format=torchscript"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYIjW4igCjqD",
        "outputId": "69cab2fb-cbfa-4acf-8e29-9c4fb6f4a38f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.0.24 üöÄ Python-3.8.10 torch-1.13.1+cu116 CPU\n",
            "YOLOv8n summary (fused): 168 layers, 3151904 parameters, 0 gradients, 8.7 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from yolov8n.pt with output shape (1, 84, 8400) (6.2 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mTorchScript:\u001b[0m starting export with torch 1.13.1+cu116...\n",
            "\u001b[34m\u001b[1mTorchScript:\u001b[0m export success ‚úÖ 1.7s, saved as yolov8n.torchscript (12.4 MB)\n",
            "\n",
            "Export complete (2.2s)\n",
            "Results saved to \u001b[1m/content\u001b[0m\n",
            "Predict:         yolo task=detect mode=predict model=yolov8n.torchscript -WARNING ‚ö†Ô∏è not yet supported for YOLOv8 exported models\n",
            "Validate:        yolo task=detect mode=val model=yolov8n.torchscript -WARNING ‚ö†Ô∏è not yet supported for YOLOv8 exported models\n",
            "Visualize:       https://netron.app\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Python Usage\n",
        "\n",
        "YOLOv8 was reimagined using Python-first principles for the most seamless Python YOLO experience yet. YOLOv8 models can be loaded from a trained checkpoint or created from scratch. Then methods are used to train, val, predict, and export the model. See a detailed Python usage examples in the YOLOv8 [Docs](https://docs.ultralytics.com/python/)."
      ],
      "metadata": {
        "id": "kUMOQ0OeDBJG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a model\n",
        "model = YOLO('yolov8n.yaml')  # build a new model from scratch\n",
        "model = YOLO('yolov8n.pt')  # load a pretrained model (recommended for training)\n",
        "\n",
        "# Use the model\n",
        "results = model.train(data='coco128.yaml', epochs=3)  # train the model\n",
        "results = model.val()  # evaluate model performance on the validation set\n",
        "results = model('https://ultralytics.com/images/bus.jpg')  # predict on an image\n",
        "success = model.export(format='onnx')  # export the model to ONNX format"
      ],
      "metadata": {
        "id": "bpF9-vS_DAaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Tasks\n",
        "\n",
        "YOLOv8 can train, val, predict and export models for the 3 primary tasks in vision AI: detection, segmentation and classification.\n",
        "\n",
        "<img width=\"1024\" src=\"https://user-images.githubusercontent.com/26833433/212094133-6bb8c21c-3d47-41df-a512-81c5931054ae.png\">\n"
      ],
      "metadata": {
        "id": "Phm9ccmOKye5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Detection\n",
        "\n",
        "YOLOv8 _detection_ models have no suffix and are the default YOLOv8 models, i.e. `yolov8n.pt` and are pretrained on COCO. See [Detection Docs](https://docs.ultralytics.com/tasks/detection/) for full details.\n"
      ],
      "metadata": {
        "id": "yq26lwpYK1lq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load YOLOv8n, train it on COCO128 for 3 epochs and predict an image with it\n",
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO('yolov8n.pt')  # load a pretrained YOLOv8n detection model\n",
        "model.train(data='coco128.yaml', epochs=3)  # train the model\n",
        "model('https://ultralytics.com/images/bus.jpg')  # predict on an image"
      ],
      "metadata": {
        "id": "8Go5qqS9LbC5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Segmentation\n",
        "\n",
        "YOLOv8 _segmentation_ models use the `-seg` suffix, i.e. `yolov8n-seg.pt` and are pretrained on COCO. See [Segmentation Docs](https://docs.ultralytics.com/tasks/segmentation/) for full details.\n"
      ],
      "metadata": {
        "id": "7ZW58jUzK66B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1vbtDQCsUH1MyOv5hUikABvrvFc1l5bqB"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UNigKufcBYx",
        "outputId": "6cfc88dc-f8af-4670-fc9a-84b0be61a476"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1vbtDQCsUH1MyOv5hUikABvrvFc1l5bqB\n",
            "To: /content/seg.pt\n",
            "\r  0% 0.00/6.76M [00:00<?, ?B/s]\r100% 6.76M/6.76M [00:00<00:00, 95.2MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 10xETRTHsVNSgfsY8ezsxDIy59Z5fTM0n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGvqB7MecgfQ",
        "outputId": "5d337bca-aa8c-40d9-98a2-49680d718605"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=10xETRTHsVNSgfsY8ezsxDIy59Z5fTM0n\n",
            "To: /content/Screenshot (37).png\n",
            "\r  0% 0.00/1.29M [00:00<?, ?B/s]\r100% 1.29M/1.29M [00:00<00:00, 80.6MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load YOLOv8n-seg, train it on COCO128-seg for 3 epochs and predict an image with it\n",
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO('yolov8n-seg.pt')  # load a pretrained YOLOv8n segmentation model\n",
        "model.train(data='coco128-seg.yaml', epochs=3)  # train the model\n",
        "model('https://ultralytics.com/images/bus.jpg')  # predict on an image"
      ],
      "metadata": {
        "id": "WFPJIQl_L5HT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!yolo task=segment mode=predict model=/content/seg.pt conf=0.25 source=/content/Screenshot.png"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uyshk6OnXz3g",
        "outputId": "18ec6249-fdad-40b1-ec69-8b0eee19722f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.0.28 üöÄ Python-3.8.10 torch-1.13.1+cu116 CUDA:0 (Tesla T4, 15110MiB)\n",
            "YOLOv8n-seg summary (fused): 195 layers, 3258649 parameters, 0 gradients, 12.0 GFLOPs\n",
            "\n",
            "image 1/1 /content/Screenshot.png: 384x640 1 pole, 2 roads, 1 rock, 22.8ms\n",
            "Speed: 0.6ms pre-process, 22.8ms inference, 51.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/segment/predict\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "_1fz8xgmaJUA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "shutil.copy(\"/content/yolov5/runs/detect/exp2/i1.mp4\", \"/content/gdrive/MyDrive/ffd/outi1.mp4\")"
      ],
      "metadata": {
        "id": "Er8WbWKVaKGg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Classification\n",
        "\n",
        "YOLOv8 _classification_ models use the `-cls` suffix, i.e. `yolov8n-cls.pt` and are pretrained on ImageNet. See [Classification Docs](https://docs.ultralytics.com/tasks/classification/) for full details.\n"
      ],
      "metadata": {
        "id": "ax3p94VNK9zR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load YOLOv8n-cls, train it on mnist160 for 3 epochs and predict an image with it\n",
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO('yolov8n-cls.pt')  # load a pretrained YOLOv8n classification model\n",
        "model.train(data='mnist160', epochs=3)  # train the model\n",
        "model('https://ultralytics.com/images/bus.jpg')  # predict on an image"
      ],
      "metadata": {
        "id": "5q9Zu6zlL5rS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEijrePND_2I"
      },
      "source": [
        "# Appendix\n",
        "\n",
        "Additional content below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMusP4OAxFu6"
      },
      "source": [
        "# Run YOLOv8 tests (git clone install only)\n",
        "!pytest ultralytics/tests"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validate multiple models\n",
        "for x in 'nsmlx':\n",
        "  !yolo val model=yolov8{x}.pt data=coco.yaml"
      ],
      "metadata": {
        "id": "Wdc6t_bfzDDk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}